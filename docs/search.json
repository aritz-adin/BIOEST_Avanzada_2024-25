[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Bioestadística Avanzada / Curso 2023-24",
    "section": "",
    "text": "Linear Mixed Models\nGeneralized Linear Mixed Models"
  },
  {
    "objectID": "index.html#exercises",
    "href": "index.html#exercises",
    "title": "Bioestadística Avanzada / Curso 2023-24",
    "section": "",
    "text": "Linear Mixed Models\nGeneralized Linear Mixed Models"
  },
  {
    "objectID": "index.html#references",
    "href": "index.html#references",
    "title": "Bioestadística Avanzada / Curso 2023-24",
    "section": "References",
    "text": "References\nDurban, M. (2014). Introducción a los Modelos Mixtos. Departamento de Estadística, UC3M.\nGallagher, J. (2023). Introduction to Generalised Linear Mixed Models using R. Statistical Services Centre Ltd.\nPinheiro, J.C., and Bates, D.M. (2000). Mixed-effects Models in S and S-PLUS. Springer Science & Business Media.\nZuur, A.F., Hilbe, J.M., and Ieno, E.N. (2013). A Beginner’s Guide to GLM and GLMM with R. Highland Statistics Ltd."
  },
  {
    "objectID": "Chapter1_Exercises.html",
    "href": "Chapter1_Exercises.html",
    "title": "Chapter 1: Linear Mixed Models",
    "section": "",
    "text": "Exercise 1: plasma data\nBelow are the results of a randomised complete block experiment to compare the effects on the clotting time of plasma (mins) of four different methods for the treatment of plasma (material extracted from Gallagher, 2023). Samples of plasma were taken from a random sample of 8 volunteers and were subjected to all 4 treatments.\n\n\n\n\nTreatment\n\n\n\n\n\n\n\nVolunteer\n1\n2\n3\n4\n\n\n1\n8.4\n9.4\n9.8\n12.2\n\n\n2\n12.8\n15.2\n12.9\n14.4\n\n\n3\n9.6\n9.1\n11.2\n9.8\n\n\n4\n9.8\n8.8\n9.9\n12.0\n\n\n5\n8.4\n8.2\n8.5\n8.5\n\n\n6\n8.6\n9.9\n9.8\n10.9\n\n\n7\n8.9\n9.0\n9.2\n10.4\n\n\n8\n7.9\n8.1\n8.2\n10.0\n\n\n\n\n1. Load the data intored in the Plasma.txt file, convert Volunteer and Treatment variables to factor, and make a descriptive plot to visualize differences between treatments and/or subjects.\n\nPlasma &lt;- read.table(\"Plasma.txt\", header=TRUE)\nhead(Plasma, n=8)\n\n  Volunteer Treatment Clotting\n1         1         1      8.4\n2         1         2      9.4\n3         1         3      9.8\n4         1         4     12.2\n5         2         1     12.8\n6         2         2     15.2\n7         2         3     12.9\n8         2         4     14.4\n\nPlasma$Volunteer &lt;- as.factor(Plasma$Volunteer)\nPlasma$Treatment &lt;- as.factor(Plasma$Treatment)\nstr(Plasma)\n\n'data.frame':   32 obs. of  3 variables:\n $ Volunteer: Factor w/ 8 levels \"1\",\"2\",\"3\",\"4\",..: 1 1 1 1 2 2 2 2 3 3 ...\n $ Treatment: Factor w/ 4 levels \"1\",\"2\",\"3\",\"4\": 1 2 3 4 1 2 3 4 1 2 ...\n $ Clotting : num  8.4 9.4 9.8 12.2 12.8 15.2 12.9 14.4 9.6 9.1 ...\n\n\nWe can make a descriptive plot of the data using the ggplot2 package\n\nlibrary(ggplot2)\n\nggplot(Plasma, aes(x=Clotting, y=Volunteer, color=Treatment)) +\n  geom_point() +\n  labs(x=\"Clotting time (mins)\", y=\"Volunteer\") +\n  theme_minimal()\n\n\n\n\nWe observe systematic differences between subjects and treatments.\n\n\n2. Which variable should be included as a fixed effect, and which as a random effect? Make a design plot to visually compare the magnitude of the effects of the Treatment and Volunteer factors.\n\nWe want to compare these particular types of treatments (experimental factor), so we use fixed effects for the Treatment factor.\nThe eight subjects represents a sample from the population about which we wish to make inferences (random factor), so we use random effects to model the Volunteer factor.\n\n\nplot.design(Clotting ~ Treatment*Volunteer, data=Plasma)\n\n\n\n\nAverage clotting time for each level of the factors Treatment and Volunteer\n\n\n\n\n\nWe see that the variability associated with the Treatment factor is lower than the variability associated with the Volunteer factor.\nWe also see that the average clotting time according to the treatment type is in the order \\(T1 \\leq T2 \\leq T3 \\leq T4\\).\n\n\n\n3. Write the linear mixed model equation.\n\\[y_{ij} = \\beta_j + u_i + \\epsilon_{ij}, \\quad i=1,\\ldots,8, \\quad j=1,\\ldots,4,\\] \\[u_i \\sim N(0,\\sigma^2_u), \\quad \\epsilon_{ij} \\sim N(0,\\sigma^2)\\] where\n\n\\(\\beta_j\\) is the mean clotting time from the \\(j\\)-th treatment\n\\(u_i\\) is a random variable associated with the \\(i\\)-th individual\n\\(\\epsilon_{ij}\\) are independent random errors\n\nUsing matrix notation\n\\[\\boldsymbol{y} = \\begin{pmatrix} \\boldsymbol{I}_4 \\\\ \\vdots \\\\ \\boldsymbol{I}_4 \\end{pmatrix} \\begin{pmatrix} \\beta_1 \\\\ \\vdots \\\\ \\beta_4 \\end{pmatrix} +\n\\begin{pmatrix}\n\\boldsymbol{1}_4 & \\boldsymbol{0} & \\ldots & \\boldsymbol{0} \\\\\n\\boldsymbol{0} & \\boldsymbol{1}_4 & \\ldots & \\boldsymbol{0} \\\\\n\\vdots & \\vdots & \\ddots & \\vdots \\\\\n\\boldsymbol{0} & \\boldsymbol{0} & \\cdots & \\boldsymbol{1}_4 \\\\\n\\end{pmatrix} \\boldsymbol{u} + \\boldsymbol{\\epsilon}\\]\n\n\n\n\n4. Test if random effects are necessary.\n\n## Fit the models ##\nlibrary(lme4)\n\nplasma.null &lt;- lm(Clotting ~ -1 + Treatment, data=Plasma)\nplasma.lmer &lt;- lmer(Clotting ~ -1 + Treatment + (1|Volunteer), data=Plasma)\n\n## LRT for the variance component sigma2_u ##\nLRT &lt;- -2*(logLik(plasma.null,REML=T)-logLik(plasma.lmer,REML=T))\nmean(1-pchisq(LRT,df=c(0,1)))\n\n[1] 2.290542e-07\n\n## Using the ranova() function from lmerTest package ##\nlibrary(lmerTest)\nranova(plasma.lmer)\n\nANOVA-like table for random-effects: Single term deletions\n\nModel:\nClotting ~ Treatment + (1 | Volunteer) - 1\n                npar  logLik    AIC    LRT Df Pr(&gt;Chisq)    \n&lt;none&gt;             6 -47.943 107.89                         \n(1 | Volunteer)    5 -60.659 131.32 25.433  1  4.581e-07 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nranova(plasma.lmer)[2,6]/2\n\n[1] 2.290542e-07\n\n## We can also use the AIC/BIC to compare the models ##\nModels &lt;- list(plasma.null=plasma.null, plasma.lmer=plasma.lmer)\ncbind(AIC=lapply(Models, AIC), BIC=lapply(Models, BIC))\n\n            AIC      BIC     \nplasma.null 134.8699 142.1986\nplasma.lmer 107.8852 116.6796\n\n\n\n\n5. Check if the treatment effect is significant.\nWe compare nested models (with and without Treatment factor) using the LRT with the anova() function base on fitting through the ML method\n\nM1 &lt;- lmer(Clotting ~ 1 + (1|Volunteer), data=Plasma, REML=FALSE)\nM2 &lt;- lmer(Clotting ~ -1 + Treatment + (1|Volunteer), data=Plasma, REML=FALSE)\nanova(M1,M2)\n\nData: Plasma\nModels:\nM1: Clotting ~ 1 + (1 | Volunteer)\nM2: Clotting ~ -1 + Treatment + (1 | Volunteer)\n   npar    AIC    BIC  logLik deviance  Chisq Df Pr(&gt;Chisq)   \nM1    3 117.77 122.17 -55.885  111.770                        \nM2    6 107.80 116.60 -47.902   95.804 15.966  3   0.001152 **\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\nWe conclude that the Treatment effect is significant.\n\n\n6. Verify whether the model assumptions are satisfied.\na) Assessing assumptions on the within-group errors\n\nplot(plasma.lmer)\n\n\n\nplot(plasma.lmer, Volunteer ~ resid(., type=\"pearson\"), abline=0, lty=2)\n\n\n\nres &lt;- resid(plasma.lmer, type=\"pearson\")\nqqnorm(res)\nqqline(res)\n\n\n\nshapiro.test(res)\n\n\n    Shapiro-Wilk normality test\n\ndata:  res\nW = 0.94578, p-value = 0.1093\n\n\n\nWe observe that the residuals are centred at zero and normally distributed, but there seems to be a lack of constant variance in the residuals (heterocedasticy).\n\nb) Assessing assumptions on the random-effects\n\nu &lt;- unlist(ranef(plasma.lmer)$Volunteer)\nqqnorm(u)\nqqline(u)\n\n\n\nshapiro.test(u)\n\n\n    Shapiro-Wilk normality test\n\ndata:  u\nW = 0.76565, p-value = 0.01215\n\n\n\nAgain, the are some issues with the assumptions for the random effects.\n\n\n\n7. Examine the model results (estimated fixed effects and variance components). Compute and interpret the intra-class correlation coefficient. Compute the predicted random effects and fitted values.\na) Estimated fixed effects and 95% confidence intervals\n\nfixef(plasma.lmer)\n\nTreatment1 Treatment2 Treatment3 Treatment4 \n    9.3000     9.7125     9.9375    11.0250 \n\nvcov(plasma.lmer)\n\n4 x 4 Matrix of class \"dpoMatrix\"\n           Treatment1 Treatment2 Treatment3 Treatment4\nTreatment1  0.4141183  0.3321317  0.3321317  0.3321317\nTreatment2  0.3321317  0.4141183  0.3321317  0.3321317\nTreatment3  0.3321317  0.3321317  0.4141183  0.3321317\nTreatment4  0.3321317  0.3321317  0.3321317  0.4141183\n\nbeta.CI &lt;- confint(plasma.lmer, parm=\"beta_\")\n\nComputing profile confidence intervals ...\n\nbeta.CI\n\n              2.5 %   97.5 %\nTreatment1 8.000009 10.59999\nTreatment2 8.412509 11.01249\nTreatment3 8.637509 11.23749\nTreatment4 9.725009 12.32499\n\nj &lt;- 4\nplot(1:j, fixef(plasma.lmer), pch=19, cex=0.5, xaxt=\"n\",\n     xlim=0.5+c(0,j), ylim=range(c(beta.CI))*c(0.9,1.1),\n     xlab=\"Type\", ylab=\"Estimated fixed effects\")\naxis(1, at=1:j, labels=rownames(beta.CI))\nsegments(1:j, beta.CI[,\"2.5 %\"], 1:j, beta.CI[,\"97.5 %\"])\n\n\n\n\nWe can use the emmeans() function to compute pairwise comparisons between treatments\n\nlibrary(emmeans)\nemmeans(plasma.lmer, pairwise~Treatment, infer=T)\n\n$emmeans\n Treatment emmean    SE   df lower.CL upper.CL t.ratio p.value\n 1           9.30 0.644 9.56     7.86     10.7  14.452  &lt;.0001\n 2           9.71 0.644 9.56     8.27     11.2  15.093  &lt;.0001\n 3           9.94 0.644 9.56     8.49     11.4  15.442  &lt;.0001\n 4          11.03 0.644 9.56     9.58     12.5  17.132  &lt;.0001\n\nDegrees-of-freedom method: kenward-roger \nConfidence level used: 0.95 \n\n$contrasts\n contrast                estimate    SE df lower.CL upper.CL t.ratio p.value\n Treatment1 - Treatment2   -0.412 0.405 21    -1.54   0.7162  -1.019  0.7405\n Treatment1 - Treatment3   -0.637 0.405 21    -1.77   0.4912  -1.574  0.4139\n Treatment1 - Treatment4   -1.725 0.405 21    -2.85  -0.5963  -4.260  0.0018\n Treatment2 - Treatment3   -0.225 0.405 21    -1.35   0.9037  -0.556  0.9440\n Treatment2 - Treatment4   -1.312 0.405 21    -2.44  -0.1838  -3.241  0.0189\n Treatment3 - Treatment4   -1.087 0.405 21    -2.22   0.0412  -2.686  0.0616\n\nDegrees-of-freedom method: kenward-roger \nConfidence level used: 0.95 \nConf-level adjustment: tukey method for comparing a family of 4 estimates \nP value adjustment: tukey method for comparing a family of 4 estimates \n\n\nTwo out of six pairwise comparisons are statistically significant at the 5% level:\n\nThe mean clotting time for treatment 4 is significantly longer than that for treatments 1 and 2.\n\nb) Estimated variance components and 95% confidence intervals\n\nVarCorr(plasma.lmer)\n\n Groups    Name        Std.Dev.\n Volunteer (Intercept) 1.63005 \n Residual              0.80987 \n\nconfint(plasma.lmer, parm=\"theta_\")\n\nComputing profile confidence intervals ...\n\n\n           2.5 %   97.5 %\n.sig01 0.9562558 2.794239\n.sigma 0.5849697 1.035247\n\n\nIntra-class correlation coefficient: \\(\\rho=\\frac{\\sigma^2_u}{\\sigma^2_u+\\sigma^2} = \\frac{1.63^2}{1.63^2+0.81^2}=0.802\\). Which means that 80.1% of the overall variability can be attributed to the differences between the individuals.\nc) Compute the predicted random effects and fitted values\n\nt(ranef(plasma.lmer)$Volunteer)\n\n                      1        2           3        4         5          6\n(Intercept) -0.04120702 3.608557 -0.06475388 0.123621 -1.501113 -0.1824882\n                     7         8\n(Intercept) -0.5827849 -1.359832\n\nplasma.fitted &lt;- cbind(Plasma,\n                       Clotting.fit=fitted(plasma.lmer),\n                       error=resid(plasma.lmer))\nhead(plasma.fitted, n=8)\n\n  Volunteer Treatment Clotting Clotting.fit       error\n1         1         1      8.4     9.258793 -0.85879298\n2         1         2      9.4     9.671293 -0.27129298\n3         1         3      9.8     9.896293 -0.09629298\n4         1         4     12.2    10.983793  1.21620702\n5         2         1     12.8    12.908557 -0.10855720\n6         2         2     15.2    13.321057  1.87894280\n7         2         3     12.9    13.546057 -0.64605720\n8         2         4     14.4    14.633557 -0.23355720\n\nplot(plasma.fitted$Clotting, plasma.fitted$Clotting.fit,\n     xlab=\"Observed\", ylab=\"Predicted\", main=\"Clotting time (mins)\")\nlines(c(0,20), c(0,20))\n\n\n\n\n\n\n\nExercise 2: spider data\nOxbrough et al. (2005) investigated how spider communities change over forestation cycles in conifer and broadleaf plantations. They identified environmental and structural features of the habitat than can be used as indicators of spider biodiversity. Different plots were surveyed, each comprising 5 to 7 sampling sites separated by a minimum of 50 metres. More than 100 species of spiders were observed.\nThe Spiders.txt file contains some of the data recorded from the original study (material extracted from Zuur et al., 2013). We are interested in analyzing the relationship between the spider diversity in each site with some environmental explanatory variables. The data set contains the following variables:\n\nDivIndex: Variable of interest. Lower values of this index indicates less abundance of different species.\nHerbLayer: Percentage of Herb Layer Cover\nLitter: Percentage of Litter Content\nGroundVeg: Percentage of Ground Vegetation\nPlot: Factor indicating the surveyed plot.\n\n\n1. Load the data intored in the Spiders.txt file and convert Plot variable to factor. Make descriptive graphs to visualize relationships between the variable of interest and the explanatory variables, taking into account the Plot factor.\n\nSpiders &lt;- read.table(\"Spiders.txt\", header=T)\nSpiders$Plot &lt;- as.factor(Spiders$Plot)\nstr(Spiders)\n\n'data.frame':   168 obs. of  5 variables:\n $ DivIndex : num  1.05 1.13 1 0.87 0.94 1.01 1.2 0.38 0.71 0.82 ...\n $ HerbLayer: num  0.27 0.45 0.63 0.49 0.32 0.73 0.68 0.2 0.39 0.38 ...\n $ GroundVeg: num  0.01 0.01 0.01 0.01 0.03 0.27 0.15 0.15 0.59 0.35 ...\n $ Litter   : num  0 0 0 0 0 0 0 0.63 0.06 0.49 ...\n $ Plot     : Factor w/ 30 levels \"1\",\"2\",\"3\",\"4\",..: 1 1 1 1 1 1 1 2 2 2 ...\n\n\nWe can make descriptive graphs of the data using the ggplot2 package\n\nlibrary(ggplot2)\n\nggplot(Spiders, aes(x=HerbLayer, y=DivIndex, color=Plot)) +\n  geom_point() +\n  labs(x=\"Percentage of Herb Layer Cover\", y=\"Diversity Index\") +\n  theme_minimal()\n\n\n\nggplot(Spiders, aes(x=Litter, y=DivIndex, color=Plot)) +\n  geom_point() +\n  labs(x=\"Percentage of Litter Content\", y=\"Diversity Index\") +\n  theme_minimal()\n\n\n\nggplot(Spiders, aes(x=GroundVeg, y=DivIndex, color=Plot)) +\n  geom_point() +\n  labs(x=\"Percentage of Ground Vegetation\", y=\"Diversity Index\") +\n  theme_minimal()\n\n\n\n\nDesign graph to compare average diversity indexes for each level of the Plot factor\n\nplot.design(DivIndex ~ Plot, data=Spiders)\n\n\n\n\n\n\n2. Test if random effects are necessary\n\n## Fit the models ##\nlibrary(lme4)\n\nspiders.null &lt;- lm(DivIndex ~ 1 + HerbLayer + Litter + GroundVeg, data=Spiders)\nspiders.lmer &lt;- lmer(DivIndex ~ 1 + HerbLayer + Litter + GroundVeg + (1|Plot), data=Spiders)\n\n## LRT for the variance component sigma2_u ##\nLRT &lt;- -2*(logLik(spiders.null,REML=T)-logLik(spiders.lmer,REML=T))\nmean(1-pchisq(LRT,df=c(0,1)))\n\n[1] 0.0002102636\n\n## Using the ranova() function from lmerTest package ##\nlibrary(lmerTest)\nranova(spiders.lmer)\n\nANOVA-like table for random-effects: Single term deletions\n\nModel:\nDivIndex ~ HerbLayer + Litter + GroundVeg + (1 | Plot)\n           npar logLik     AIC    LRT Df Pr(&gt;Chisq)    \n&lt;none&gt;        6 98.715 -185.43                         \n(1 | Plot)    5 92.495 -174.99 12.439  1  0.0004205 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nranova(spiders.lmer)[2,6]/2\n\n[1] 0.0002102636\n\n\n\n\n3. Check which environmental variables should be included in the model.\nWe compare nested models:\n\nM0 &lt;- lmer(DivIndex ~ 1 + (1|Plot), data=Spiders, REML=FALSE)\nM1 &lt;- lmer(DivIndex ~ 1 + HerbLayer + (1|Plot), data=Spiders, REML=FALSE)\nM2 &lt;- lmer(DivIndex ~ 1 + HerbLayer + Litter + (1|Plot), data=Spiders, REML=FALSE)\nM3 &lt;- lmer(DivIndex ~ 1 + HerbLayer + Litter + GroundVeg + (1|Plot), data=Spiders, REML=FALSE)\nanova(M0,M1,M2,M3)\n\nData: Spiders\nModels:\nM0: DivIndex ~ 1 + (1 | Plot)\nM1: DivIndex ~ 1 + HerbLayer + (1 | Plot)\nM2: DivIndex ~ 1 + HerbLayer + Litter + (1 | Plot)\nM3: DivIndex ~ 1 + HerbLayer + Litter + GroundVeg + (1 | Plot)\n   npar     AIC     BIC  logLik deviance   Chisq Df Pr(&gt;Chisq)    \nM0    3 -186.68 -177.31  96.339  -192.68                          \nM1    4 -198.50 -186.01 103.252  -206.50 13.8261  1  0.0002005 ***\nM2    5 -205.88 -190.26 107.940  -215.88  9.3759  1  0.0021985 ** \nM3    6 -204.26 -185.52 108.132  -216.26  0.3830  1  0.5360224    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\nWe conclude that the only the HerbLayer and Litter covariates are statistically significant.\nWe can also check if a interaction between these two variables should be included in the model\n\nM4 &lt;- lmer(DivIndex ~ 1 + HerbLayer + Litter + HerbLayer*Litter + (1|Plot), data=Spiders, REML=FALSE)\nanova(M2,M4)\n\nData: Spiders\nModels:\nM2: DivIndex ~ 1 + HerbLayer + Litter + (1 | Plot)\nM4: DivIndex ~ 1 + HerbLayer + Litter + HerbLayer * Litter + (1 | Plot)\n   npar     AIC     BIC logLik deviance  Chisq Df Pr(&gt;Chisq)\nM2    5 -205.88 -190.26 107.94  -215.88                     \nM4    6 -204.09 -185.34 108.05  -216.09 0.2089  1     0.6476\n\n\n\n\n4. Fit the final linear mixed model and write its equation\nWe fit the following linear mixed model \\[y_{ij} = \\beta_0 + \\beta_1 \\times HerbLayer_{ij} + \\beta_2 \\times Litter_{ij} + u_i + \\epsilon_{ij}\\] \\[u_i \\sim N(0,\\sigma^2_u), \\quad \\epsilon_{ij} \\sim N(0,\\sigma^2)\\] where\n\n\\(y_{ij}\\) is the diversity index at site \\(j\\) in plot \\(i\\)\n\\(\\beta_0\\) is a global intercept\n\\(\\beta_1\\) and \\(\\beta_2\\) are regression coefficients associated with the continuous covariates HerbLayer and Litter, respectively\n\\(u_i\\) is a random variable associated with the \\(i\\)-th surveyed plot\n\\(\\epsilon_{ij}\\) are independent random errors\n\n\n## Final model ##\nModel &lt;- lmer(DivIndex ~ 1 + HerbLayer + Litter + (1|Plot), data=Spiders)\nsummary(Model)\n\nLinear mixed model fit by REML. t-tests use Satterthwaite's method [\nlmerModLmerTest]\nFormula: DivIndex ~ 1 + HerbLayer + Litter + (1 | Plot)\n   Data: Spiders\n\nREML criterion at convergence: -201.3\n\nScaled residuals: \n    Min      1Q  Median      3Q     Max \n-3.6298 -0.4518  0.0329  0.5959  2.6373 \n\nRandom effects:\n Groups   Name        Variance Std.Dev.\n Plot     (Intercept) 0.004145 0.06438 \n Residual             0.013854 0.11770 \nNumber of obs: 168, groups:  Plot, 30\n\nFixed effects:\n             Estimate Std. Error        df t value Pr(&gt;|t|)    \n(Intercept)   0.93674    0.01994  51.53734  46.985  &lt; 2e-16 ***\nHerbLayer     0.16628    0.04301 127.12493   3.866 0.000175 ***\nLitter       -0.22189    0.07077 157.44148  -3.135 0.002048 ** \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nCorrelation of Fixed Effects:\n          (Intr) HrbLyr\nHerbLayer -0.609       \nLitter    -0.278  0.026\n\n\n\n\n5. Verify whether the model assumptions are satisfied.\na) Assessing assumptions on the within-group errors\n\nplot(Model)\n\n\n\nplot(Model, Plot ~ resid(., type=\"pearson\"), abline=0, lty=2)\n\n\n\nres &lt;- resid(Model, type=\"pearson\")\nqqnorm(res)\nqqline(res)\n\n\n\nshapiro.test(res)\n\n\n    Shapiro-Wilk normality test\n\ndata:  res\nW = 0.96873, p-value = 0.0007681\n\n\nb) Assessing assumptions on the random effects\n\nu &lt;- unlist(ranef(Model)$Plot)\nqqnorm(u)\nqqline(u)\n\n\n\nshapiro.test(u)\n\n\n    Shapiro-Wilk normality test\n\ndata:  u\nW = 0.96304, p-value = 0.3695\n\n\n\n\n6. Examine the model results (estimated fixed effects and variance components). Compute and interpret the intra-class correlation coefficient. Make a plot of observed vs predicted diversity index values.\na) Estimated fixed effects and 95% confidence intervals\n\nfixef(Model)\n\n(Intercept)   HerbLayer      Litter \n  0.9367414   0.1662767  -0.2218901 \n\nbeta.CI &lt;- confint(Model, parm=\"beta_\")\n\nComputing profile confidence intervals ...\n\nbeta.CI\n\n                  2.5 %     97.5 %\n(Intercept)  0.89767549  0.9755674\nHerbLayer    0.08255604  0.2501822\nLitter      -0.36550678 -0.0822844\n\n\nb) Estimated variance components and 95% confidence intervals\n\nVarCorr(Model)\n\n Groups   Name        Std.Dev.\n Plot     (Intercept) 0.064379\n Residual             0.117703\n\nconfint(Model, parm=\"theta_\")\n\nComputing profile confidence intervals ...\n\n\n            2.5 %     97.5 %\n.sig01 0.03582034 0.09292245\n.sigma 0.10450819 0.13254556\n\n\nIntra-class correlation coefficient: \\(\\rho=\\frac{\\sigma^2_u}{\\sigma^2_u+\\sigma^2} = \\frac{0.0644^2}{0.0644^2+0.1177^2}=0.23\\). Which means that only 23% of the overall variability can be attributed to the differences between the surveyed plots.\nc) Compare observed and predicted diversity index values\n\nspiders.fitted &lt;- cbind(Spiders,\n                        DivIndex.fit=fitted(Model),\n                        error=resid(Model))\nhead(spiders.fitted)\n\n  DivIndex HerbLayer GroundVeg Litter Plot DivIndex.fit       error\n1     1.05      0.27      0.01      0    1    0.9863934  0.06360665\n2     1.13      0.45      0.01      0    1    1.0163232  0.11367684\n3     1.00      0.63      0.01      0    1    1.0462530 -0.04625298\n4     0.87      0.49      0.01      0    1    1.0229742 -0.15297423\n5     0.94      0.32      0.03      0    1    0.9947072 -0.05470719\n6     1.01      0.73      0.27      0    1    1.0628806 -0.05288065\n\nplot(spiders.fitted$DivIndex, spiders.fitted$DivIndex.fit,\n     xlab=\"Observed\", ylab=\"Predicted\", main=\"Diversity Index\",\n     xlim=c(0.4,1.5), ylim=c(0.4,1.5))\nlines(c(0,2),c(0,2))\n\n\n\n\n\n\n\nExercise 3: split-plot experiment on varieties of oats\nThese data have been introduced by Yates (1935) as an example of a split-plot design (material extracted from Durban, 2014). The experimental units were arranged into six block using a \\(3 \\times 4\\) full factorial design, with three varieties of oats and four nitrogen concentrations. The term full factorial means that every variety was used with every nitrogen concentration.\n\nOats &lt;- read.table(\"Oats.txt\", header=T, stringsAsFactors = T)\nhead(Oats, n=12)\n\n   Block     Variety nitro yield\n1      I     Victory   0.0   111\n2      I     Victory   0.2   130\n3      I     Victory   0.4   157\n4      I     Victory   0.6   174\n5      I Golden Rain   0.0   117\n6      I Golden Rain   0.2   114\n7      I Golden Rain   0.4   161\n8      I Golden Rain   0.6   141\n9      I  Marvellous   0.0   105\n10     I  Marvellous   0.2   140\n11     I  Marvellous   0.4   118\n12     I  Marvellous   0.6   156\n\nstr(Oats)\n\n'data.frame':   72 obs. of  4 variables:\n $ Block  : Factor w/ 6 levels \"I\",\"II\",\"III\",..: 1 1 1 1 1 1 1 1 1 1 ...\n $ Variety: Factor w/ 3 levels \"Golden Rain\",..: 3 3 3 3 1 1 1 1 2 2 ...\n $ nitro  : num  0 0.2 0.4 0.6 0 0.2 0.4 0.6 0 0.2 ...\n $ yield  : int  111 130 157 174 117 114 161 141 105 140 ...\n\nlibrary(ggplot2)\n\nggplot(Oats, aes(x=factor(nitro), y=yield, color=Variety)) +\n  geom_line(aes(group=Variety)) + \n  geom_point() + \n  labs(x=\"Nitrogen concentration\", y=\"Yield\") +\n  ggtitle(\"Yield of oats by variety and nitrogen level\") +\n  facet_wrap(~ Block, ncol=2) +\n  theme_minimal()\n\n\n\n\nDesign graph to compare average yields for each level of Block, Variety and nitro factors\n\nplot.design(yield ~ Block*Variety*factor(nitro), data=Oats)\n\n\n\n\n\n1. Test if random effects are necessary\n\n\n\n\n\n2. Choose the correct structure for the fixed effects\n\n\n\n\n3. Fit the final linear mixed model and write its equation\n\n\n\n\n\n\n\n\n\n\n\n4. Verify whether the model assumptions are satisfied.\na) Assessing assumptions on the within-group errors\nb) Assessing assumptions on the random-effects\n\n\n5. Examine the model results.\na) Estimated fixed effects and 95% confidence intervals\nb) Estimated variance components and 95% confidence intervals\n\n\nc) Predicted random effects and yield values"
  },
  {
    "objectID": "Chapter2_Exercises.html",
    "href": "Chapter2_Exercises.html",
    "title": "Chapter 2: Generalized Linear Mixed Models",
    "section": "",
    "text": "Exercise 1\nData from a clinical trial, involving 2 treatments (control and active drug), conducted at 11 randomly selected centres are discussed by Beitler and Landis (1985). For the \\(i\\)-th center and \\(j\\)-th treatment, the proportion of \\(n_{ij}\\) patients having a positive response (\\(y_{ij}\\)) is recorded below (material extracted from Gallagher, 2023):\n\n\n\nCentre\nTreatment\n\\(y_{ij}\\)\n\\(n_{ij}\\)\n\n\n\n\n1\ndrug\n11\n36\n\n\n1\ncontrol\n10\n37\n\n\n2\ndrug\n16\n20\n\n\n2\ncontrol\n22\n32\n\n\n3\ndrug\n14\n19\n\n\n3\ncontrol\n7\n19\n\n\n\\(\\ldots\\)\n\\(\\ldots\\)\n\\(\\ldots\\)\n\\(\\ldots\\)\n\n\n\n\n1. Load the data intored in the multicentre.txt file, convert centre variables to factor, and make a descriptive plot to visualize differences between treatments and/or centers.\n\nmulticentre &lt;- read.table(file=\"multicentre.txt\", header=T, stringsAsFactors=T)\nhead(multicentre)\n\n  centre   treat  y  n       obs\n1      1    drug 11 36 0.3055556\n2      1 control 10 37 0.2702703\n3      2    drug 16 20 0.8000000\n4      2 control 22 32 0.6875000\n5      3    drug 14 19 0.7368421\n6      3 control  7 19 0.3684211\n\nmulticentre$centre &lt;- as.factor(multicentre$centre)\nstr(multicentre)\n\n'data.frame':   22 obs. of  5 variables:\n $ centre: Factor w/ 11 levels \"1\",\"2\",\"3\",\"4\",..: 1 1 2 2 3 3 4 4 5 5 ...\n $ treat : Factor w/ 2 levels \"control\",\"drug\": 2 1 2 1 2 1 2 1 2 1 ...\n $ y     : int  11 10 16 22 14 7 2 1 6 0 ...\n $ n     : int  36 37 20 32 19 19 16 17 17 12 ...\n $ obs   : num  0.306 0.27 0.8 0.688 0.737 ...\n\n\nWe can make a descriptive plot of the data using the ggplot2 package\n\nlibrary(ggplot2)\n\nlibrary(ggplot2)\nggplot(multicentre, aes(x=obs, y=centre, color=treat)) +\n  geom_point() +\n  labs(x=\"Observed probability\", y=\"Centre\")\n\n\n\n\nWe observe systematic differences between centres.\n\n\n2. Which variable should be included as a fixed effect, and which as a random effect? Make a design plot to visually compare the magnitude of the effects of the centre and treat factors.\n\nWe want to compare these particular treatments (experimental factor), so we use fixed effects for the treat factor.\nThe eleven centres represents a random sample from the population about which we wish to make inferences (random factor), so we use random effects to model the center factor.\n\n\nplot.design(obs ~ treat*centre, data=multicentre)\n\n\n\n\nAverage observed probabilities for each level of the factors treat and center\n\n\n\n\n\nWe see that the variability associated with the treatment is much lower than the variability associated with the centres.\nWe also see that the average probability of a positive response is higher in the active drug treatment.\n\n\n\n3. Write the mixed logistic regression model equation.\n\\[y_{ij} | u_i  \\sim Bin(n_{ij},\\pi_{ij}), \\quad i=1,\\ldots,10 \\quad \\mbox{and} \\quad j=1,2\\] \\[\\mbox{logit}(\\pi_{ij}) = \\beta_0 + \\beta_1*x_{ij} + u_i, \\quad u_i \\sim N(0,\\sigma_u^2)\\] where\n\n\\(\\pi_{ij}\\) is the probability of a favourable outcome in a patient on the \\(i\\)-th centre and \\(j\\)-th treatment\n\\(x_{ij}\\) is an indicator variable for treatment (0=control, 1=active drug)\n\\(u_i\\) is a random variable associated with the \\(i\\)-th centre\n\n\n\n4. Choose the correct structure for the random effects\n\n\n5. Check if the treatment effect is significant.\nWe compare nested models (with and without treat factor) using the LRT with the anova() function\n\n\n\n6. Using the model with fixed and random effects, which is the probability of a positive response on the active drug group? Interpret the odds ratio \\(e^{\\beta_1}\\) and compute a 95% confidence interval.\n\n\n\n\n7. Using the best model, verify whether the model assumptions on the random effects are satisfied.\n\n\n\n8. Which is the estimated variance and 95% confidence interval of the within-centre random effect? Compute and interpret the intra-class correlation coefficient.\n\n\n\n9. Compute the predicted probabilties of a positive response for each value of the dataset. Include those estimated probabilities in the descriptive plot of section 1).\n\nmulticentre$pred &lt;- predict(Model, newdata=multicentre, type=\"response\")\nhead(multicentre)\n\n  centre   treat  y  n       obs      pred\n1      1    drug 11 36 0.3055556 0.3337400\n2      1 control 10 37 0.2702703 0.3337400\n3      2    drug 16 20 0.8000000 0.5178894\n4      2 control 22 32 0.6875000 0.5178894\n5      3    drug 14 19 0.7368421 0.4391549\n6      3 control  7 19 0.3684211 0.4391549\n\nggplot(multicentre, aes(x=obs, y=centre, color=treat)) +\n  geom_point() +\n  geom_point(aes(x=pred, y=centre), shape=8, color=\"black\") + \n  labs(x=\"Prob\", y=\"Centre\")\n\n\n\n\nObserved (dots) and predicted (asterisks) probabilities of a positive response for each centre"
  },
  {
    "objectID": "Chapter1_Exercises.html#table-of-contents",
    "href": "Chapter1_Exercises.html#table-of-contents",
    "title": "Chapter 1: Linear Mixed Models",
    "section": "",
    "text": "Exercise 1: plasma data\nExercise 2: spider data"
  }
]